import os
import lmdb
import pickle
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tqdm import tqdm

# --- 1. –ê–†–•–ò–¢–ï–ö–¢–£–†–ê (MLP) ---
class BindingPredictorHead(nn.Module):
    def __init__(self, input_dim=1792, hidden_dim=1024, dropout=0.1):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1)
        )

    def forward(self, x):
        return self.net(x).squeeze(-1)

# --- 2. –£–¢–ò–õ–ò–¢–´ ---
def get_lmdb_keys(target_ids, index_path):
    print(f"üìñ –ß–∏—Ç–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞: {index_path}")
    try:
        # –ß–∏—Ç–∞–µ–º index.csv, –≥–¥–µ –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ (–∏–ª–∏ 'id') - —ç—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω—ã–π ID
        # –ê –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ (index) - —ç—Ç–æ —Ç–æ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å –¥–ª—è –∫–ª—é—á–∞ emb_{idx}
        
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤ index.csv –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫. –ï—Å–ª–∏ –Ω–µ—Ç - –¥–æ–±–∞–≤—å header=None
        # –û–±—ã—á–Ω–æ —Ç–∞–º: id, smiles, sequence...
        df = pd.read_csv(index_path) 
        
        # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ —Å ID –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è 'mol_id' –∏–ª–∏ 'id'
        id_col = 'id' if 'id' in df.columns else df.columns[0]
        
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É '{id_col}' –∫–∞–∫ ID.")
        
        # –î–µ–ª–∞–µ–º –∫–æ–ª–æ–Ω–∫—É ID —Å—Ç—Ä–æ–∫–æ–≤–æ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        df[id_col] = df[id_col].astype(str)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ —Å—Ç—Ä–æ–∫–∏, ID –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –≤ –Ω–∞—à–µ–º —Å–ø–∏—Å–∫–µ –ª–∞–∫—Ç–æ–º–∞–∑
        target_set = set(str(x) for x in target_ids)
        mask = df[id_col].isin(target_set)
        
        found_df = df[mask].copy()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–∏: emb_{row_index}
        # –í–∞–∂–Ω–æ: row_index —ç—Ç–æ –∏–Ω–¥–µ–∫—Å –≤ DataFrame, –µ—Å–ª–∏ –º—ã —á–∏—Ç–∞–ª–∏ –µ–≥–æ —Ü–µ–ª–∏–∫–æ–º –±–µ–∑ —á–∞–Ω–∫–æ–≤
        # df.index —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–æ–∫–∏ (0, 1, 2...)
        mapping = []
        for idx in found_df.index:
            glob_id = found_df.at[idx, id_col]
            # –í–û–¢ –û–ù, –ö–õ–Æ–ß–ï–í–û–ô –ú–û–ú–ï–ù–¢: –ø—Ä–µ—Ñ–∏–∫—Å emb_
            key_bytes = f"emb_{idx}".encode()
            mapping.append((glob_id, key_bytes))
            
        return mapping
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–Ω–¥–µ–∫—Å–æ–≤: {e}")
        return []

def plot_results(y_true, y_pred, output_path):
    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', lw=2)
    sns.scatterplot(x=y_true, y=y_pred, alpha=0.6)
    plt.title(f"R¬≤ = {r2_score(y_true, y_pred):.3f}")
    
    plt.subplot(1, 2, 2)
    sns.histplot(y_true - y_pred, bins=30, kde=True, color='purple')
    plt.title(f"MAE = {mean_absolute_error(y_true, y_pred):.3f}")
    
    plt.savefig(output_path, dpi=300)
    plt.close()

# --- 3. MAIN ---
def main():
    # –ü—É—Ç–∏ (Binding Core context)
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    PROJECT_ROOT = os.path.dirname(BASE_DIR) # /scratch/ivanb/projects/Diplom
    DATA_ROOT = os.path.join(PROJECT_ROOT, "data", "baseline")
    
    IDS_PATH = os.path.join(DATA_ROOT, "splits_transfer", "lactamase_all_ids.csv")
    INDEX_PATH = os.path.join(DATA_ROOT, "index.csv")
    # –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ: –∏—â–µ–º –≤ db_embeddings, —Ä–∞–∑ —Å–∫—Ä–∏–ø—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–≤–∞–ª –∏–º–µ–Ω–Ω–æ –µ–≥–æ
    DB_PATH = os.path.join(DATA_ROOT, "db_embeddings") 
    MODEL_PATH = os.path.join(BASE_DIR, "experiments", "MLP_Fusion_Emb_v1", "best_model.pt")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ Device: {device}")

    # 1. ID –õ–∞–∫—Ç–æ–º–∞–∑
    print(f"üìÇ ID –ª–∞–∫—Ç–æ–º–∞–∑: {IDS_PATH}")
    lact_ids = pd.read_csv(IDS_PATH, header=None, dtype=str).iloc[:, 0].tolist()
    
    # 2. –ú–∞–ø–ø–∏–Ω–≥ (ID -> emb_N)
    key_mapping = get_lmdb_keys(lact_ids, INDEX_PATH)
    if not key_mapping:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ index.csv. –ü—Ä–æ–≤–µ—Ä—å –∫–æ–ª–æ–Ω–∫—É ID.")
        return
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–π: {len(key_mapping)}")

    # 3. –ß—Ç–µ–Ω–∏–µ –±–∞–∑—ã
    print(f"üì¶ –ß–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {DB_PATH}")
    X_list = []
    y_list = []
    
    # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –∏–∑ —Ç–≤–æ–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞:
    # {'embedding': np.array(...), 'target': float}
    
    env = lmdb.open(DB_PATH, readonly=True, lock=False)
    with env.begin() as txn:
        for glob_id, key_bytes in tqdm(key_mapping):
            data = txn.get(key_bytes)
            if data is None:
                continue
            
            obj = pickle.loads(data)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ —Å–ª–æ–≤–∞—Ä—è
            X_list.append(obj['embedding'])
            y_list.append(obj['target'])
            
    env.close()

    if not X_list:
        print("‚ùå –ö–ª—é—á–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã (emb_N), –Ω–æ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–µ –Ω–µ—Ç. –ë–∞–∑–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ –∏–Ω–¥–µ–∫—Å—ã —Å–º–µ—â–µ–Ω—ã?")
        return

    # 4. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
    X = torch.tensor(np.array(X_list), dtype=torch.float32).to(device)
    y_true = np.array(y_list)
    
    print(f"üß† –ú–æ–¥–µ–ª—å: {MODEL_PATH}")
    model = BindingPredictorHead(input_dim=1792, hidden_dim=1024).to(device).eval()
    state = torch.load(MODEL_PATH, map_location=device)
    
    new_state = {}
    for k, v in state.items():
        k = k.replace("head.", "net.")
        if not k.startswith("net."): k = "net." + k
        new_state[k] = v
    model.load_state_dict(new_state, strict=False)

    print("üî• –ò–Ω—Ñ–µ—Ä–µ–Ω—Å...")
    with torch.no_grad():
        preds = model(X).cpu().numpy()

    # 5. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    mae = mean_absolute_error(y_true, preds)
    r2 = r2_score(y_true, preds)
    
    print(f"\nüìä MAE: {mae:.4f} | R¬≤: {r2:.4f}")
    
    df_res = pd.DataFrame({"actual": y_true, "pred": preds, "error": np.abs(y_true - preds)})
    df_res.to_csv("lactamase_predictions.csv", index=False)
    plot_results(y_true, preds, "lactamase_audit.png")

if __name__ == "__main__":
    main()
