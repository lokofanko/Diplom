import sys
import os
import yaml
import argparse
import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from clearml import Task
from sklearn.metrics import mean_absolute_error, mean_squared_error

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# –ò–º–ø–æ—Ä—Ç—ã
from src.architectures.fusion import BindingPredictor
from src.utils.dataset import BindingLMDBDataset
# Collate –Ω–∞–º –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω –∫–∞—Å—Ç–æ–º–Ω—ã–π, –±–µ—Ä–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
from torch.utils.data._utils.collate import default_collate

def calculate_metrics(preds, targets):
    """–°—á–∏—Ç–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ (MAE, RMSE, MAPE)."""
    preds = np.array(preds)
    targets = np.array(targets)
    
    mae = mean_absolute_error(targets, preds)
    rmse = np.sqrt(mean_squared_error(targets, preds))
    
    # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å –¥–ª—è MAPE
    epsilon = 1e-8
    mape = np.mean(np.abs((targets - preds) / (targets + epsilon))) * 100
    
    return mae, rmse, mape

def run_epoch(model, loader, criterion, optimizer, device, is_train, logger, global_step, log_interval):
    """–û–¥–Ω–∞ —ç–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
    model.train(is_train)
    total_loss = 0.0
    all_preds = []
    all_targets = []
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    context = torch.enable_grad() if is_train else torch.no_grad()
    
    # Progress bar
    pbar = tqdm(loader, desc="Train" if is_train else "Val", leave=False)
    
    with context:
        for batch in pbar:
            # –ü–µ—Ä–µ–Ω–æ—Å –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU
            mol_input = {k: v.to(device) for k, v in batch['mol_input'].items()}
            prot_input = {k: v.to(device) for k, v in batch['prot_input'].items()}
            targets = batch['targets'].to(device)
            
            # Forward
            preds = model(prot_input, mol_input)
            loss = criterion(preds, targets)
            
            # Backward (—Ç–æ–ª—å–∫–æ –¥–ª—è Train)
            if is_train:
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ —ç–ø–æ—Ö–∏
                if logger and (global_step % log_interval == 0):
                    logger.report_scalar("Batch Loss", "Train", iteration=global_step, value=loss.item())
                global_step += 1
                
                pbar.set_postfix({'loss': loss.item()})
            
            total_loss += loss.item()
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –º–µ—Ç—Ä–∏–∫ (–Ω–∞ CPU)
            all_preds.extend(preds.cpu().detach().numpy())
            all_targets.extend(targets.cpu().detach().numpy())
            
    # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ —ç–ø–æ—Ö—É
    avg_loss = total_loss / len(loader)
    mae, rmse, mape = calculate_metrics(all_preds, all_targets)
    
    return avg_loss, mae, rmse, mape, global_step

def main(config_path):
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞
    with open(config_path, 'r') as f:
        cfg = yaml.safe_load(f)

    # 2. ClearML
    task = Task.init(
        project_name=cfg['project_name'], 
        task_name=cfg['experiment_name']
    )
    task.connect(cfg)
    logger = task.get_logger()

    device = torch.device(cfg['training']['device'] if torch.cuda.is_available() else "cpu")
    print(f"üöÄ Device: {device}")

    # 3. –î–∞–Ω–Ω—ã–µ (–ò—Å–ø–æ–ª—å–∑—É–µ–º –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ê–ù–ù–£–Æ –±–∞–∑—É)
    print("üíø Loading Preprocessed Data...")
    proc_db_path = cfg['paths']['processed_db_path']
    splits_dir = cfg['paths']['splits_dir']

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –±–∞–∑—ã
    if not os.path.exists(proc_db_path):
        print(f"‚ùå –û–®–ò–ë–ö–ê: –ë–∞–∑–∞ {proc_db_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ scripts/preprocess_data.py")
        return

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (–±–µ–∑ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞, —Ç.–∫. –¥–∞–Ω–Ω—ã–µ —É–∂–µ –≥–æ—Ç–æ–≤—ã)
    train_ds = BindingLMDBDataset(proc_db_path, os.path.join(splits_dir, 'train_indices.csv'))
    val_ds = BindingLMDBDataset(proc_db_path, os.path.join(splits_dir, 'val_indices.csv'))
    test_ds = BindingLMDBDataset(proc_db_path, os.path.join(splits_dir, 'test_indices.csv'))

    kwargs = {
        'batch_size': cfg['training']['batch_size'],
        'num_workers': cfg['training']['num_workers'],
        'pin_memory': True,
        'collate_fn': None # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π collate, —Ç.–∫. –¥–∞–Ω–Ω—ã–µ —É–∂–µ —Ç–µ–Ω–∑–æ—Ä—ã
    }
    
    train_loader = DataLoader(train_ds, shuffle=True, **kwargs)
    val_loader = DataLoader(val_ds, shuffle=False, **kwargs)
    test_loader = DataLoader(test_ds, shuffle=False, **kwargs)

    # 4. –ú–æ–¥–µ–ª—å
    print("üß† Building Model...")
    
    # --- FIX: –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π ---
    model_args = cfg['model'].copy()
    if 'type' in model_args:
        del model_args['type'] # –£–¥–∞–ª—è–µ–º –∫–ª—é—á 'type', –∫–æ—Ç–æ—Ä—ã–π –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–ø–∫—É —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (–Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏)
    # cfg['paths']['prot_model_path'] = "../models/pretrained/protbert" -> –Ω–∞–º –Ω—É–∂–Ω–æ "../models/pretrained"
    base_model_dir = os.path.dirname(cfg['paths']['prot_model_path'])

    model = BindingPredictor(
        base_model_dir=base_model_dir, 
        **model_args
    ).to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=cfg['training']['learning_rate'])
    criterion = nn.MSELoss()

    # 5. –û–±—É—á–µ–Ω–∏–µ
    print("üî• Starting Training...")
    best_val_mae = float('inf') 
    global_step = 0
    
    # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    exp_dir = os.path.join(cfg['paths']['save_dir'], cfg['experiment_name'])
    os.makedirs(exp_dir, exist_ok=True)

    for epoch in range(cfg['training']['epochs']):
        print(f"\n=== EPOCH {epoch+1}/{cfg['training']['epochs']} ===")
        
        # Train
        t_loss, t_mae, t_rmse, t_mape, global_step = run_epoch(
            model, train_loader, criterion, optimizer, device, True, 
            logger, global_step, cfg['training']['log_step_interval']
        )
        print(f"TRAIN | Loss: {t_loss:.4f} | MAE: {t_mae:.4f} | MAPE: {t_mape:.2f}%")
        
        # Val
        v_loss, v_mae, v_rmse, v_mape, _ = run_epoch(
            model, val_loader, criterion, None, device, False, 
            logger, global_step, cfg['training']['log_step_interval']
        )
        print(f"VAL   | Loss: {v_loss:.4f} | MAE: {v_mae:.4f} | MAPE: {v_mape:.2f}%")

        # ClearML Logs
        logger.report_scalar("Epoch MAE", "Train", iteration=epoch, value=t_mae)
        logger.report_scalar("Epoch MAE", "Val", iteration=epoch, value=v_mae)
        logger.report_scalar("Epoch MAPE", "Val", iteration=epoch, value=v_mape)

        # Save Best Model
        if v_mae < best_val_mae:
            best_val_mae = v_mae
            save_path = os.path.join(exp_dir, "best_model.pt")
            torch.save(model.state_dict(), save_path)
            print(f"üíæ Saved best model to {save_path} (MAE: {best_val_mae:.4f})")

    # 6. –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç
    print("\nüß™ Testing Best Model...")
    best_model_path = os.path.join(exp_dir, "best_model.pt")
    model.load_state_dict(torch.load(best_model_path))
    
    test_loss, test_mae, test_rmse, test_mape, _ = run_epoch(
        model, test_loader, criterion, None, device, False, None, 0, 0
    )
    
    print(f"\nüèÜ FINAL TEST RESULTS:")
    print(f"MAE:  {test_mae:.4f}")
    print(f"RMSE: {test_rmse:.4f}")
    print(f"MAPE: {test_mape:.2f}%")
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ ClearML
    logger.report_single_value("Final_Test_MAE", test_mae)
    logger.report_single_value("Final_Test_MAPE", test_mape)
    logger.report_single_value("Final_Test_RMSE", test_rmse)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="configs/predictor_fusion.yaml")
    args = parser.parse_args()
    main(args.config)